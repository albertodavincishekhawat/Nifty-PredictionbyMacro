{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Market Prediction Using Macro Economic Data**\n",
    "using LSTM and TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and cleaning  data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **\"niftyvix\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"MacroData/fniftyvix_data.csv\")\n",
    "niftyvix = df0.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# niftyvix = niftyvix.rename(columns={'Date.1': 'Date'})\n",
    "# niftyvix = niftyvix.drop(\"Date.1\", axis=1)\n",
    "niftyvix = niftyvix.drop(\"Date.1\", axis=1)\n",
    "niftyvix['Date'] =  pd.to_datetime(niftyvix['Date'])\n",
    "niftyvix.head(1)\n",
    "niftyvix.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niftyvix = niftyvix.drop(niftyvix.columns[[5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,46,47,48,49,50]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "niftyvix.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Above dataframe will be used as a template to clean and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dates must be in ascending order, hence DFs are being reciprocaled as necessary\n",
    "\n",
    "> All date formats are being matched with \"niftyvix\" DF\n",
    "\n",
    "> Copy of each orignal df is being made so that it stays safe\n",
    "\n",
    "> All dates are changed from object to datetime format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **\"Gold\"** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"MacroData/Gold.csv\")\n",
    "gold = df1.copy()\n",
    "gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unecesssary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = gold[['Date','GoldPrice','GoldChange %']]\n",
    "gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change columns to right data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold['Date']=pd.to_datetime(gold['Date'])\n",
    "\n",
    "gold['GoldPrice']=gold['GoldPrice'].astype(str).str.replace(',','')\n",
    "gold['GoldPrice']=gold['GoldPrice'].astype(float)\n",
    "\n",
    "gold['GoldChange %']=gold['GoldChange %'].astype(str).str.replace(\"%\",\"\")\n",
    "gold['GoldChange %']=gold['GoldChange %'].astype(float)\n",
    "\n",
    "gold['Date'] =  pd.to_datetime(gold['Date'])\n",
    "\n",
    "gold.info()\n",
    "gold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date i.e, index is not in accending order so we will correct it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = gold.iloc[::-1].reset_index(drop=True)\n",
    "gold.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Crude Oil**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"MacroData/Crudeoil.csv\")\n",
    "crude = df2.copy()\n",
    "crude.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping uncessecary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crude = crude[[\"Date\",\"CrudePrice\",\"CrudeChange %\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing columns to right datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crude['Date']=pd.to_datetime(crude['Date'])\n",
    "\n",
    "crude['CrudePrice']=crude['CrudePrice'].astype(str).str.replace(',','')\n",
    "crude['CrudePrice']=crude['CrudePrice'].astype(float)\n",
    "\n",
    "crude['CrudeChange %']=crude['CrudeChange %'].astype(str).str.replace(\"%\",\"\")\n",
    "crude['CrudeChange %']=crude['CrudeChange %'].astype(float)\n",
    "\n",
    "crude.info()\n",
    "crude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **USDINR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"MacroData/usdinr.csv\")\n",
    "usdinr = df3.copy()\n",
    "usdinr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping uncessecary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdinr = usdinr[[\"Date\",\"inrPrice\",\"inrChange %\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing columns to right datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdinr['Date']=pd.to_datetime(usdinr['Date'])\n",
    "\n",
    "usdinr['inrPrice']=usdinr['inrPrice'].astype(str).str.replace(',','')\n",
    "usdinr['inrPrice']=usdinr['inrPrice'].astype(float)\n",
    "\n",
    "usdinr['inrChange %']=usdinr['inrChange %'].astype(str).str.replace(\"%\",\"\")\n",
    "usdinr['inrChange %']=usdinr['inrChange %'].astype(float)\n",
    "\n",
    "usdinr.info()\n",
    "usdinr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date is not accending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdinr = usdinr.iloc[::-1].reset_index(drop=True)\n",
    "usdinr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **\"US Dollar Index\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_csv(\"MacroData/USdollarindex.csv\")\n",
    "usdindex = df4.copy()\n",
    "usdindex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping uncessecary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdindex = usdindex[[\"Date\",\"diPrice\",\"diChange %\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing columns to right datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdindex['Date']=pd.to_datetime(usdindex['Date'])\n",
    "\n",
    "usdindex['diPrice']=usdindex['diPrice'].astype(str).str.replace(',','')\n",
    "usdindex['diPrice']=usdindex['diPrice'].astype(float)\n",
    "\n",
    "usdindex['diChange %']=usdindex['diChange %'].astype(str).str.replace(\"%\",\"\")\n",
    "usdindex['diChange %']=usdindex['diChange %'].astype(float)\n",
    "\n",
    "usdindex.info()\n",
    "usdindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date is not accending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdindex = usdindex.iloc[::-1].reset_index(drop=True)\n",
    "usdindex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10-2year bond yeild**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(\"MacroData/10-2year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[\"Date\"] = pd.to_datetime(df5['Date'])\n",
    "df5.info()\n",
    "df5.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting **T10Y2Y** column from object type to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df5[\"T10Y2Y\"] = df5['T10Y2Y'].astype(float)\n",
    "\n",
    "# df5.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> it gives an error \n",
    "\n",
    "ValueError: could not convert string to float: \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be multiple '.' values in the column let us convert them to NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['T10Y2Y']=df5['T10Y2Y'].replace(\".\", np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\".\" is converted to NaN successfully. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[12:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will fill the NaN values with preceding values and check if it's working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['T10Y2Y'] = df5['T10Y2Y'].fillna(method='ffill')    # method = \"ffill\" fills NaN values with previous values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if any NaN values are left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df5['T10Y2Y'].isna().sum())  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All NaN values are filled with preceding values succcessfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[\"T10Y2Y\"] = df5['T10Y2Y'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[12:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding **\"percent change\"** as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['T10Y2Y%chng'] = df5['T10Y2Y'].pct_change() * 100\n",
    "T10Y2Ydf = df5.copy()\n",
    "T10Y2Ydf['Date'] =  pd.to_datetime(T10Y2Ydf['Date'])\n",
    "T10Y2Ydf.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T10Y2Ydf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a NaN value in first row, we will make it zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T10Y2Ydf[\"T10Y2Y%chng\"] = T10Y2Ydf['T10Y2Y%chng'].fillna('0').astype(float)\n",
    "T10Y2Ydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T10Y2Ydf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we will join all above DFs togather priortising the Dates of \"niftyvix\" DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge each DataFrame one by one, ensuring 'Date' index is maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = niftyvix\n",
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, gold, how='left', on='Date')\n",
    "daily_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, crude, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, usdinr, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, usdindex, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, T10Y2Ydf, how='left', on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are null values in GOLD data so we will fix it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.ffill(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all the DataFrames above were with daily frequency, Now below we will deal with the DataFrames that were not in daily frequency "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fed Interest Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(\"MacroData/Fedinterest.csv\")\n",
    "fedinterest = df6.copy()\n",
    "fedinterest[\"Date\"] = pd.to_datetime(fedinterest['Date'])\n",
    "fedinterest.info()\n",
    "fedinterest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, fedinterest, how='left', on='Date')\n",
    "daily_df.ffill(inplace=True)\n",
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RBI Interest Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = pd.read_csv(\"MacroData/Rbiinterest.csv\")\n",
    "rbiinterest = df7.copy()\n",
    "rbiinterest[\"Date\"] = pd.to_datetime(rbiinterest['Date'])\n",
    "rbiinterest.info()\n",
    "rbiinterest.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, rbiinterest, how='left', on='Date')\n",
    "daily_df.ffill(inplace=True)\n",
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **US Inflation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.read_csv(\"MacroData/USinflationdata.csv\")\n",
    "USinflation = df8.copy()\n",
    "USinflation[\"Date\"] = pd.to_datetime(USinflation['Date'])\n",
    "USinflation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding a column that shows percentage change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USinflation['USInflationRate%chng'] = USinflation['USInflation Rate (%)'].pct_change() * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USinflation['USInflationRate%chng']=USinflation['USInflationRate%chng'].fillna('0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, USinflation, how='left', on='Date')\n",
    "daily_df.ffill(inplace=True)\n",
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USinflation.info()\n",
    "USinflation.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **India Inflation Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.read_csv(\"MacroData/IndiaInflation.csv\")\n",
    "IndiaInflation = df9.copy()\n",
    "IndiaInflation[\"Date\"] = pd.to_datetime(IndiaInflation['Date'])\n",
    "IndiaInflation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndiaInflation['IndiaInflationRate(%)chng'] = IndiaInflation['IndiaInflationRate(%)'].pct_change() * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndiaInflation['IndiaInflationRate(%)chng']=IndiaInflation['IndiaInflationRate(%)chng'].fillna('0').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IndiaInflation.info()\n",
    "IndiaInflation.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, IndiaInflation, how='left', on='Date')\n",
    "daily_df.ffill(inplace=True)\n",
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can observe that there are about **17** rows that are NaN in the begning of data out of **4015** entries so we can replace them with most recent available entry\n",
    "\n",
    "Columns with NaN values are as below\n",
    "\n",
    "**Fedinterest,\tFed%change,\tRbiinterest,\tRbi%change,\tUSInflation Rate (%),\tUSInflationRate%chng,\tIndiaInflationRate(%),\tIndiaInflationRate(%)chng**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['Fedinterest'] = daily_df['Fedinterest'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['Fed%change'] = daily_df['Fed%change'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['Rbiinterest'] = daily_df['Rbiinterest'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['Rbi%change'] = daily_df['Rbi%change'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['USInflation Rate (%)'] = daily_df['USInflation Rate (%)'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['USInflationRate%chng'] = daily_df['USInflationRate%chng'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['IndiaInflationRate(%)'] = daily_df['IndiaInflationRate(%)'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['IndiaInflationRate(%)chng'] = daily_df['IndiaInflationRate(%)chng'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.ffill(inplace=True)\n",
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IndianBudgetDates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10 = pd.read_csv(\"MacroData/IndianBudgetDates.csv\")\n",
    "IndianBudgetDates = df10.copy()\n",
    "IndianBudgetDates[\"Date\"] = pd.to_datetime(IndianBudgetDates['Date'])\n",
    "IndianBudgetDates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding above df in dialy_df and filling NaN values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, IndianBudgetDates, how='left', on='Date')\n",
    "daily_df['IndiaBudgetDatesMarker'].fillna(0)\n",
    "daily_df['IndiaBudgetDatesMarker'].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create **Feature** which will help machine anticepate the Indian Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the counter and output list\n",
    "# counter = 0\n",
    "# anticipation = []\n",
    "\n",
    "# # Loop through the column values\n",
    "# for value in daily_df[\"IndiaBudgetDatesMarker\"]:\n",
    "#     if value == 1:\n",
    "#         counter = 0  # Reset counter when marker is 1\n",
    "#     anticipation.append(counter)\n",
    "#     counter += 1\n",
    "\n",
    "# # Assign the output list to a new column\n",
    "# daily_df[\"IndiaBudgetDatesAnticipation\"] = anticipation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_anticipation(df, marker_column, output_column):\n",
    "    counter = 0\n",
    "    anticipation = []\n",
    "\n",
    "    for value in df[marker_column]:\n",
    "        if value == 1:\n",
    "            counter = 0  # Reset counter when marker is 1\n",
    "        anticipation.append(counter)\n",
    "        counter += 1\n",
    "\n",
    "    df[output_column] = anticipation\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_anticipation(daily_df, \"IndiaBudgetDatesMarker\", \"IndiaBudgetDatesAnticipation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of **\"IndiaBudgetDatesAnticipation\" is reseting** at new budget event so we can say it's working, **now we can drop \"IndiaBudgetDatesMarker\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_df.drop(\"IndiaBudgetDatesMarker\", axis=1)\n",
    "daily_df.info()\n",
    "daily_df[1:-136]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing columns to right datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IndiaElectionDates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = pd.read_csv(\"MacroData/IndiaElectionDates.csv\")\n",
    "IndiaElectionDates = df11.copy()\n",
    "IndiaElectionDates[\"Date\"] = pd.to_datetime(IndiaElectionDates['Date'])\n",
    "IndiaElectionDates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding above df in dialy_df and filling NaN values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, IndiaElectionDates, how='left', on='Date')\n",
    "daily_df['IndiaElectionDatesMarker'].fillna(0)\n",
    "daily_df['IndiaElectionDatesMarker'].head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and adding **\"anticepation\"** feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_anticipation(daily_df, \"IndiaElectionDatesMarker\", \"IndiaElectionDatesAnticipation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if new feature is added correctly and droping the marker column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = daily_df.drop(\"IndiaElectionDatesMarker\", axis=1)\n",
    "daily_df.info()\n",
    "daily_df[1:-136]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **UsElectionDates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df12 = pd.read_csv(\"MacroData/UsElectionDates.csv\")\n",
    "UsElectionDates = df12.copy()\n",
    "UsElectionDates[\"Date\"] = pd.to_datetime(UsElectionDates['Date'])\n",
    "UsElectionDates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding above df in dialy_df and filling NaN values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df = pd.merge(daily_df, UsElectionDates, how='left', on='Date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df['UsElectionDatesMarker'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_df.head(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and adding **\"anticepation\"** feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_anticipation(daily_df, \"UsElectionDatesMarker\", \"UsElectionDatesAnticepation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
